{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking with xarray and dask\n",
    "\n",
    "A basic example of loading a netCDF4 dataset using `xarray`, chunking it using `dask`, and saving it to disk in `zarr` format\n",
    "\n",
    "Author: Charles Blackmon-Luca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "We start by importing the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import dask\n",
    "import zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we are using developmental versions of `xarray` and `zarr` - this is so we can take advantage of `zarr`'s consolidated metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11.1+64.g612d390\n",
      "2.2.1.dev140\n"
     ]
    }
   ],
   "source": [
    "print(xr.__version__)\n",
    "print(zarr.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a grasp of dask's functionality beyond cloud computing, we will also use a local distributed scheduler, which can be viewed by starting up a `Client` through `dask.distributed`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:45868\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>16</li>\n",
       "  <li><b>Memory: </b>135.44 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:45868' processes=4 cores=16>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "client  = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the progress of this scheduler by following the link above to the Dashboard - we will need to forward port `8787` to our local machine using `ssh -L`:\n",
    "\n",
    "```\n",
    "ssh -L 8787:localhost:8787 tracmip@weather.rsmas.miami.edu\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly data\n",
    "\n",
    "With the dashboard open, let's try opening a random dataset - ECHAM-6.3's LandOrbit experiment with a monthly timestep. When working with data we find is commonly used for climatologies, we may prefer to chunk by time, as we'd prefer to load the entire space for any given plot or computation. When working with pressure-sensitive data, we may prefer to chunk by pressure levels. Overall, take into consideration that we want our chunks to be around 10-100 MB in size; when in doubt, use `'auto'` to quickly select chunk sizes you *think* may need to be chunked but don't necessarily know a good size for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (lat: 96, lon: 192, plev: 17, time: 480)\n",
       "Coordinates:\n",
       "  * lon      (lon) float64 0.0 1.875 3.75 5.625 7.5 ... 352.5 354.4 356.2 358.1\n",
       "  * lat      (lat) float64 88.57 86.72 84.86 83.0 ... -83.0 -84.86 -86.72 -88.57\n",
       "  * plev     (plev) float64 1e+05 9.25e+04 8.5e+04 7e+04 ... 3e+03 2e+03 1e+03\n",
       "  * time     (time) datetime64[ns] 2066-01-30T23:52:00 ... 2105-12-30T23:52:00\n",
       "Data variables:\n",
       "    cl       (time, plev, lat, lon) float32 dask.array<shape=(480, 17, 96, 192), chunksize=(160, 10, 96, 192)>\n",
       "    cli      (time, plev, lat, lon) float32 dask.array<shape=(480, 17, 96, 192), chunksize=(160, 10, 96, 192)>\n",
       "    clivi    (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    clt      (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    clw      (time, plev, lat, lon) float32 dask.array<shape=(480, 17, 96, 192), chunksize=(160, 10, 96, 192)>\n",
       "    clwvi    (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    evspsbl  (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    hfls     (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    hfss     (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    hur      (time, plev, lat, lon) float32 dask.array<shape=(480, 17, 96, 192), chunksize=(160, 10, 96, 192)>\n",
       "    hus      (time, plev, lat, lon) float32 dask.array<shape=(480, 17, 96, 192), chunksize=(160, 10, 96, 192)>\n",
       "    pr       (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    prc      (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    prsn     (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    prw      (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    ps       (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    psl      (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    rlds     (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    rldscs   (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    rlus     (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    rlut     (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    rlutcs   (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    rsds     (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    rsdscs   (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    rsdt     (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    rsus     (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    rsuscs   (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    rsut     (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    rsutcs   (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    sfcWind  (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    ta       (time, plev, lat, lon) float32 dask.array<shape=(480, 17, 96, 192), chunksize=(160, 10, 96, 192)>\n",
       "    tas      (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    tauu     (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    tauv     (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    ts       (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    ua       (time, plev, lat, lon) float32 dask.array<shape=(480, 17, 96, 192), chunksize=(160, 10, 96, 192)>\n",
       "    uas      (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    va       (time, plev, lat, lon) float32 dask.array<shape=(480, 17, 96, 192), chunksize=(160, 10, 96, 192)>\n",
       "    vas      (time, lat, lon) float32 dask.array<shape=(480, 96, 192), chunksize=(480, 96, 192)>\n",
       "    wap      (time, plev, lat, lon) float32 dask.array<shape=(480, 17, 96, 192), chunksize=(160, 10, 96, 192)>\n",
       "    zg       (time, plev, lat, lon) float32 dask.array<shape=(480, 17, 96, 192), chunksize=(160, 10, 96, 192)>\n",
       "Attributes:\n",
       "    CDI:          Climate Data Interface version 1.7.0 (http://mpimet.mpg.de/...\n",
       "    Conventions:  CF-1.4\n",
       "    history:      Wed Dec  2 00:07:04 2015: ncrename -d lev,plev -v lev,plev ...\n",
       "    source:       ECHAM6\n",
       "    institution:  Max-Planck-Institute for Meteorology\n",
       "    CDO:          Climate Data Operators version 1.7.0 (http://mpimet.mpg.de/..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly = xr.open_mfdataset('/data2/tracmip/ECHAM-6.3/LandOrbit/Amon/*.nc').chunk(chunks={'time' : 'auto', 'plev' : 'auto'})\n",
    "monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the data loaded and chunked, we can convert it to `zarr`, where the chunking will be retained. This process shouldn't take very long, as the amount of data is relatively small; the progress of this conversion can be viewed from our dashboard. Note our option `consolidated=True`, which will opt to store metadata for each variable in one single file rather than in each chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x7f1a2b875a58>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!rm -rf /data2/tracmip/zarr/test/\n",
    "monthly.to_zarr('/data2/tracmip/zarr/test/', consolidated=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is saved to disk, we can inspect the chunk size in terminal to make sure it is reasonable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 292M\n",
      "-rw------- 1 tracmip tracmip 59M Feb 21 15:27 0.0.0.0\n",
      "-rw------- 1 tracmip tracmip 39M Feb 21 15:27 0.1.0.0\n",
      "-rw------- 1 tracmip tracmip 59M Feb 21 15:27 1.0.0.0\n",
      "-rw------- 1 tracmip tracmip 39M Feb 21 15:27 1.1.0.0\n",
      "-rw------- 1 tracmip tracmip 59M Feb 21 15:27 2.0.0.0\n",
      "-rw------- 1 tracmip tracmip 39M Feb 21 15:27 2.1.0.0\n"
     ]
    }
   ],
   "source": [
    "!ls -lh /data2/tracmip/zarr/test/zg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily data\n",
    "\n",
    "The monthly data is chunked well, but it is not representative of the data that would benefit from cloud computing. A better example is LandOrbit data with a daily timestep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (lat: 96, lon: 192, plev: 17, time: 3600)\n",
       "Coordinates:\n",
       "  * lon      (lon) float64 0.0 1.875 3.75 5.625 7.5 ... 352.5 354.4 356.2 358.1\n",
       "  * lat      (lat) float64 88.57 86.72 84.86 83.0 ... -83.0 -84.86 -86.72 -88.57\n",
       "  * plev     (plev) float64 1e+05 9.25e+04 8.5e+04 7e+04 ... 3e+03 2e+03 1e+03\n",
       "  * time     (time) datetime64[ns] 2096-01-01T23:52:00 ... 2105-12-30T23:52:00\n",
       "Data variables:\n",
       "    cl       (time, plev, lat, lon) float32 dask.array<shape=(3600, 17, 96, 192), chunksize=(720, 2, 96, 192)>\n",
       "    cli      (time, plev, lat, lon) float32 dask.array<shape=(3600, 17, 96, 192), chunksize=(720, 2, 96, 192)>\n",
       "    clivi    (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    clt      (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    clw      (time, plev, lat, lon) float32 dask.array<shape=(3600, 17, 96, 192), chunksize=(720, 2, 96, 192)>\n",
       "    clwvi    (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    evspsbl  (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    hfls     (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    hfss     (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    hur      (time, plev, lat, lon) float32 dask.array<shape=(3600, 17, 96, 192), chunksize=(720, 2, 96, 192)>\n",
       "    hus      (time, plev, lat, lon) float32 dask.array<shape=(3600, 17, 96, 192), chunksize=(720, 2, 96, 192)>\n",
       "    pr       (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    prc      (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    prsn     (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    prw      (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    ps       (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    psl      (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    rlds     (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    rldscs   (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    rlus     (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    rlut     (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    rlutcs   (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    rsds     (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    rsdscs   (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    rsdt     (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    rsus     (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    rsuscs   (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    rsut     (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    rsutcs   (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    sfcWind  (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    ta       (time, plev, lat, lon) float32 dask.array<shape=(3600, 17, 96, 192), chunksize=(720, 2, 96, 192)>\n",
       "    tas      (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    tauu     (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    tauv     (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    ts       (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    ua       (time, plev, lat, lon) float32 dask.array<shape=(3600, 17, 96, 192), chunksize=(720, 2, 96, 192)>\n",
       "    uas      (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    va       (time, plev, lat, lon) float32 dask.array<shape=(3600, 17, 96, 192), chunksize=(720, 2, 96, 192)>\n",
       "    vas      (time, lat, lon) float32 dask.array<shape=(3600, 96, 192), chunksize=(1800, 96, 192)>\n",
       "    wap      (time, plev, lat, lon) float32 dask.array<shape=(3600, 17, 96, 192), chunksize=(720, 2, 96, 192)>\n",
       "    zg       (time, plev, lat, lon) float32 dask.array<shape=(3600, 17, 96, 192), chunksize=(720, 2, 96, 192)>\n",
       "Attributes:\n",
       "    CDI:          Climate Data Interface version 1.7.0 (http://mpimet.mpg.de/...\n",
       "    Conventions:  CF-1.4\n",
       "    history:      Wed Dec  2 00:28:28 2015: ncrename -d lev,plev -v lev,plev ...\n",
       "    source:       ECHAM6\n",
       "    institution:  Max-Planck-Institute for Meteorology\n",
       "    CDO:          Climate Data Operators version 1.7.0 (http://mpimet.mpg.de/..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily = xr.open_mfdataset('/data2/tracmip/ECHAM-6.3/LandOrbit/Aday/*.nc').chunk(chunks={'time' : 'auto', 'plev' : 'auto'})\n",
    "daily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process should take notably longer, but still benefits from the `Client` we initialized above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x7f1a2b4eb710>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!rm -rf /data2/tracmip/zarr/test/\n",
    "daily.to_zarr('/data2/tracmip/zarr/test/', consolidated=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can imagine, there are much more chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2.3G\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 0.0.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 0.1.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 0.2.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 0.3.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 0.4.0.0\n",
      "-rw------- 1 tracmip tracmip 54M Feb 21 15:28 0.5.0.0\n",
      "-rw------- 1 tracmip tracmip 53M Feb 21 15:28 0.6.0.0\n",
      "-rw------- 1 tracmip tracmip 52M Feb 21 15:28 0.7.0.0\n",
      "-rw------- 1 tracmip tracmip 26M Feb 21 15:28 0.8.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 1.0.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 1.1.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 1.2.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 1.3.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 1.4.0.0\n",
      "-rw------- 1 tracmip tracmip 54M Feb 21 15:28 1.5.0.0\n",
      "-rw------- 1 tracmip tracmip 53M Feb 21 15:28 1.6.0.0\n",
      "-rw------- 1 tracmip tracmip 52M Feb 21 15:28 1.7.0.0\n",
      "-rw------- 1 tracmip tracmip 26M Feb 21 15:28 1.8.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 2.0.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 2.1.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 2.2.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 2.3.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 2.4.0.0\n",
      "-rw------- 1 tracmip tracmip 54M Feb 21 15:28 2.5.0.0\n",
      "-rw------- 1 tracmip tracmip 53M Feb 21 15:28 2.6.0.0\n",
      "-rw------- 1 tracmip tracmip 52M Feb 21 15:28 2.7.0.0\n",
      "-rw------- 1 tracmip tracmip 25M Feb 21 15:28 2.8.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 3.0.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 3.1.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 3.2.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 3.3.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 3.4.0.0\n",
      "-rw------- 1 tracmip tracmip 54M Feb 21 15:28 3.5.0.0\n",
      "-rw------- 1 tracmip tracmip 53M Feb 21 15:28 3.6.0.0\n",
      "-rw------- 1 tracmip tracmip 52M Feb 21 15:28 3.7.0.0\n",
      "-rw------- 1 tracmip tracmip 26M Feb 21 15:28 3.8.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 4.0.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 4.1.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 4.2.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 4.3.0.0\n",
      "-rw------- 1 tracmip tracmip 56M Feb 21 15:28 4.4.0.0\n",
      "-rw------- 1 tracmip tracmip 54M Feb 21 15:28 4.5.0.0\n",
      "-rw------- 1 tracmip tracmip 53M Feb 21 15:28 4.6.0.0\n",
      "-rw------- 1 tracmip tracmip 52M Feb 21 15:28 4.7.0.0\n",
      "-rw------- 1 tracmip tracmip 26M Feb 21 15:28 4.8.0.0\n"
     ]
    }
   ],
   "source": [
    "!ls -lh /data2/tracmip/zarr/test/zg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once in `zarr` format, we can interact with the datasets through `zarr`'s own interface, which is more compatible with JupyterLab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"zarr-info\"><tbody><tr><th style=\"text-align: left\">Name</th><td style=\"text-align: left\">/zg</td></tr><tr><th style=\"text-align: left\">Type</th><td style=\"text-align: left\">zarr.core.Array</td></tr><tr><th style=\"text-align: left\">Data type</th><td style=\"text-align: left\">float32</td></tr><tr><th style=\"text-align: left\">Shape</th><td style=\"text-align: left\">(3600, 17, 96, 192)</td></tr><tr><th style=\"text-align: left\">Chunk shape</th><td style=\"text-align: left\">(720, 2, 96, 192)</td></tr><tr><th style=\"text-align: left\">Order</th><td style=\"text-align: left\">C</td></tr><tr><th style=\"text-align: left\">Read-only</th><td style=\"text-align: left\">False</td></tr><tr><th style=\"text-align: left\">Compressor</th><td style=\"text-align: left\">Blosc(cname='lz4', clevel=5, shuffle=SHUFFLE, blocksize=0)</td></tr><tr><th style=\"text-align: left\">Store type</th><td style=\"text-align: left\">zarr.storage.DirectoryStore</td></tr><tr><th style=\"text-align: left\">No. bytes</th><td style=\"text-align: left\">4512153600 (4.2G)</td></tr><tr><th style=\"text-align: left\">No. bytes stored</th><td style=\"text-align: left\">2416182052 (2.3G)</td></tr><tr><th style=\"text-align: left\">Storage ratio</th><td style=\"text-align: left\">1.9</td></tr><tr><th style=\"text-align: left\">Chunks initialized</th><td style=\"text-align: left\">45/45</td></tr></tbody></table>"
      ],
      "text/plain": [
       "Name               : /zg\n",
       "Type               : zarr.core.Array\n",
       "Data type          : float32\n",
       "Shape              : (3600, 17, 96, 192)\n",
       "Chunk shape        : (720, 2, 96, 192)\n",
       "Order              : C\n",
       "Read-only          : False\n",
       "Compressor         : Blosc(cname='lz4', clevel=5, shuffle=SHUFFLE, blocksize=0)\n",
       "Store type         : zarr.storage.DirectoryStore\n",
       "No. bytes          : 4512153600 (4.2G)\n",
       "No. bytes stored   : 2416182052 (2.3G)\n",
       "Storage ratio      : 1.9\n",
       "Chunks initialized : 45/45"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zgroup = zarr.open('/data2/tracmip/zarr/test/')\n",
    "zgroup.zg.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can get some insight on what type of data is contained, and how it is stored and compressed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
